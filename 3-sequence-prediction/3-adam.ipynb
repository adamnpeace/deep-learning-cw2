{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "!curl -fsS https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip -o /tmp/trainDevTestTrees_PTB.zip\n",
    "!unzip -q -o -d ./data /tmp/trainDevTestTrees_PTB.zip\n",
    "!rm -f /tmp/trainDevTestTrees_PTB.zip\n",
    "\n",
    "def loadsst(path):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    file1 = open(path, 'r')\n",
    "    Lines = file1.readlines()\n",
    "    for line in Lines:\n",
    "        soup = line.split()\n",
    "        ys.append(int(soup[0].lstrip('(')))\n",
    "        tokens = []\n",
    "        for chunk in soup[2:]:\n",
    "            if not chunk.endswith(\")\"):\n",
    "                continue\n",
    "            tokens.append(chunk.rstrip(')'))\n",
    "        xs.append(tokens)\n",
    "    return xs, ys\n",
    "\n",
    "ssttrainxs, ssttrainys = loadsst(\"./data/trees/train.txt\")\n",
    "sstvalidxs, sstvalidys = loadsst(\"./data/trees/dev.txt\")\n",
    "ssttestxs, ssttestys = loadsst(\"./data/trees/test.txt\")\n",
    "\n",
    "def normalize(s):\n",
    "    for i in range(len(s)):\n",
    "        replacements = [(\" ,\", \",\"), (\" .\", \".\"), (\" '\", \"'\"), \n",
    "                        (\"\\/\", \"/\"), (\" ;\", \";\"), (\" :\", \":\"),\n",
    "                        (\" %\", \"%\"), (u\"æ\", \"ae\"), (u\"Æ\", \"AE\"), \n",
    "                        (u\"œ\", \"oe\"), (u\"Œ\", \"OE\"), (\"-LRB- \", \"(\"), \n",
    "                        (\" -RRB-\", \")\"), (\"-LRB-\", \"(\"), (\"-RRB-\", \")\"),\n",
    "                        (\" n't\", \"n't\"), (\"`` \", '\"'), (\"``\", '\"'),\n",
    "                        (\"''\", '\"'), (\"` \", \"'\"), (\"$ \", \"$\"),\n",
    "                        (\" !\", \"!\"), (\"\\\\\", \"\")]\n",
    "        for to_replace, replacement in replacements:\n",
    "            s = s.replace(to_replace, replacement)\n",
    "    # https://stackoverflow.com/a/518232/2809427\n",
    "    def unicodeToAscii(s):\n",
    "        allowed_chars = string.ascii_letters + ' .,;:\\'-#!/\"=&$|_'\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "            and c in allowed_chars\n",
    "        )\n",
    "    return unicodeToAscii(s)\n",
    "\n",
    "def get_normalized_dataset(dataset):\n",
    "    return [normalize(\" \".join(sentence)) for sentence in dataset]\n",
    "\n",
    "trainxs_corpus = \"_\".join(get_normalized_dataset(ssttrainxs))\n",
    "validxs_corpus = \"_\".join(get_normalized_dataset(sstvalidxs))\n",
    "testxs_corpus = \"_\".join(get_normalized_dataset(ssttestxs))\n",
    "\n",
    "seq_len = 200\n",
    "\n",
    "corpus_to_ss = lambda corpus: [corpus[(i*200):((i+1)*200)] for i in range(len(corpus) // seq_len)]\n",
    "trainxs_sentences = corpus_to_ss(trainxs_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4292 sentences, 67 letters in vocab, max seq len is 200\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(list(set(trainxs_corpus)))\n",
    "n_sentences, vocab_size = len(trainxs_sentences), len(vocab)\n",
    "maxlen = len(max(trainxs_sentences, key=len))\n",
    "char_to_idx = { ch:idx for idx,ch in enumerate(vocab) }\n",
    "idx_to_char = { idx:ch for idx,ch in enumerate(vocab) }\n",
    "print(\"{} sentences, {} letters in vocab, max seq len is {}\".format(n_sentences, vocab_size, maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_inputs(sentences, maxlen):\n",
    "    for i in range(len(sentences)):\n",
    "        while len(sentences[i]) < maxlen:\n",
    "            sentences[i] += ' '\n",
    "    return sentences\n",
    "trainxs = pad_inputs(trainxs_sentences, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_target(ss):\n",
    "    \"\"\"Get input and target from padded sentences\"\"\"\n",
    "    input_ss = []\n",
    "    target_ss = []\n",
    "    for i in range(len(ss)):\n",
    "        input_ss.append([char_to_idx[c] for c in ss[i][:-1]])\n",
    "        target_ss.append([char_to_idx[c] for c in ss[i][1:]])\n",
    "    return input_ss, target_ss\n",
    "input_ss, target_ss = get_input_target(trainxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 48, 45, 0, 31, 55, 43, 51, 0, 49, 59, 0, 44, 45, 59, 60, 49, 54, 45, 44, 0, 60, 55, 0, 42, 45, 0, 60, 48, 45, 0, 59, 60, 0, 16, 45, 54, 60, 61, 58, 65, 6, 59, 0, 54, 45, 63, 0, 2, 16, 55, 54, 41, 54, 2, 0, 41, 54, 44, 0, 60, 48, 41, 60, 0, 48, 45, 6, 59, 0, 47, 55, 49, 54, 47, 0, 60, 55, 0, 53, 41, 51, 45, 0, 41, 0, 59, 56, 52, 41, 59, 48, 0, 45, 62, 45, 54, 0, 47, 58, 45, 41, 60, 45, 58, 0, 60, 48, 41, 54, 0, 14, 58, 54, 55, 52, 44, 0, 32, 43, 48, 63, 41, 58, 66, 45, 54, 45, 47, 47, 45, 58, 7, 0, 23, 45, 41, 54, 8, 16, 52, 41, 61, 44, 0, 35, 41, 54, 0, 17, 41, 53, 53, 45, 0, 55, 58, 0, 32, 60, 45, 62, 45, 54, 0, 32, 45, 47, 41, 52, 9, 40, 33, 48, 45, 0, 47, 55, 58, 47, 45, 55, 61, 59, 52, 65, 0, 45, 52, 41, 42, 55, 58, 41, 60, 45, 0, 43, 55]\n",
      "[48, 45, 0, 31, 55, 43, 51, 0, 49, 59, 0, 44, 45, 59, 60, 49, 54, 45, 44, 0, 60, 55, 0, 42, 45, 0, 60, 48, 45, 0, 59, 60, 0, 16, 45, 54, 60, 61, 58, 65, 6, 59, 0, 54, 45, 63, 0, 2, 16, 55, 54, 41, 54, 2, 0, 41, 54, 44, 0, 60, 48, 41, 60, 0, 48, 45, 6, 59, 0, 47, 55, 49, 54, 47, 0, 60, 55, 0, 53, 41, 51, 45, 0, 41, 0, 59, 56, 52, 41, 59, 48, 0, 45, 62, 45, 54, 0, 47, 58, 45, 41, 60, 45, 58, 0, 60, 48, 41, 54, 0, 14, 58, 54, 55, 52, 44, 0, 32, 43, 48, 63, 41, 58, 66, 45, 54, 45, 47, 47, 45, 58, 7, 0, 23, 45, 41, 54, 8, 16, 52, 41, 61, 44, 0, 35, 41, 54, 0, 17, 41, 53, 53, 45, 0, 55, 58, 0, 32, 60, 45, 62, 45, 54, 0, 32, 45, 47, 41, 52, 9, 40, 33, 48, 45, 0, 47, 55, 58, 47, 45, 55, 61, 59, 52, 65, 0, 45, 52, 41, 42, 55, 58, 41, 60, 45, 0, 43, 55, 54]\n"
     ]
    }
   ],
   "source": [
    "print(input_ss[0])\n",
    "print(target_ss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "seq_len = maxlen - 1\n",
    "batch_size = n_sentences\n",
    "n_epochs = 300\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(ss, vocab_size, seq_len, batch_size):\n",
    "    tensor = torch.zeros(batch_size, seq_len, vocab_size)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(seq_len):\n",
    "            tensor[i, j, ss[i][j]] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ohe = one_hot_encode(input_ss, vocab_size, seq_len, batch_size)\n",
    "target_tensor = torch.Tensor(target_ss) # No OHE necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available: device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, 1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output, nextHidden = self.rnn(input, hidden)\n",
    "        output = self.fc(output)\n",
    "        return output, nextHidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=vocab_size, output_size=vocab_size, hidden_size=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): RNN(67, 23, batch_first=True)\n",
       "  (fc): Linear(in_features=23, out_features=67, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/300............. Loss: 3.2083\n",
      "Epoch: 20/300............. Loss: 3.0929\n",
      "Epoch: 30/300............. Loss: 3.0290\n",
      "Epoch: 40/300............. Loss: 2.9462\n",
      "Epoch: 50/300............. Loss: 2.8463\n",
      "Epoch: 60/300............. Loss: 2.7479\n",
      "Epoch: 70/300............. Loss: 2.6624\n",
      "Epoch: 80/300............. Loss: 2.5935\n",
      "Epoch: 90/300............. Loss: 2.5375\n",
      "Epoch: 100/300............. Loss: 2.4930\n",
      "Epoch: 110/300............. Loss: 2.4596\n",
      "Epoch: 120/300............. Loss: 2.4335\n",
      "Epoch: 130/300............. Loss: 2.4122\n",
      "Epoch: 140/300............. Loss: 2.3929\n",
      "Epoch: 150/300............. Loss: 2.3773\n",
      "Epoch: 160/300............. Loss: 2.3632\n",
      "Epoch: 170/300............. Loss: 2.3500\n",
      "Epoch: 180/300............. Loss: 2.3372\n",
      "Epoch: 190/300............. Loss: 2.3249\n",
      "Epoch: 200/300............. Loss: 2.3129\n",
      "Epoch: 210/300............. Loss: 2.3014\n",
      "Epoch: 220/300............. Loss: 2.2912\n",
      "Epoch: 230/300............. Loss: 2.2795\n",
      "Epoch: 240/300............. Loss: 2.2685\n",
      "Epoch: 250/300............. Loss: 2.2582\n",
      "Epoch: 260/300............. Loss: 2.2480\n",
      "Epoch: 270/300............. Loss: 2.2385\n",
      "Epoch: 280/300............. Loss: 2.2299\n",
      "Epoch: 290/300............. Loss: 2.2217\n",
      "Epoch: 300/300............. Loss: 2.2143\n"
     ]
    }
   ],
   "source": [
    "def train(input_ohe, target_tensor, n_epochs):\n",
    "    loss_ary = []\n",
    "    target_tensor = target_tensor.to(device)\n",
    "    input_ohe = input_ohe.to(device)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        hidden = rnn.init_hidden(batch_size).to(device)\n",
    "        output, hidden = rnn(input_ohe, hidden)\n",
    "        loss = criterion(output.view(-1, vocab_size), target_tensor.view(-1).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch%10 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "        loss_ary.append(loss)\n",
    "    return rnn, loss_ary\n",
    "rnn, loss_ary = train(input_ohe, target_tensor, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.7143075466156006, 4.33110294342041)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_ary)\n",
    "plt.ylim(min(loss_ary).item()-0.5, max(loss_ary).item()+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(model, s, argmax=False):\n",
    "    batch_size = 1\n",
    "    s_tensor = torch.tensor([char_to_idx[c] for c in s]).unsqueeze(0)\n",
    "    s_ohe = one_hot_encode(s_tensor, vocab_size, s_tensor.size(1), batch_size)\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    out, hidden = model(s_ohe, hidden)\n",
    "    prob = F.softmax(out, dim=2)\n",
    "    \n",
    "    last_prob = prob[0, -1]\n",
    "    argmax_idx = last_prob.argmax().item()\n",
    "    sample_idx = last_prob.multinomial(num_samples=1, replacement=True)\n",
    "    pred_char = idx_to_char[sample_idx.item()]\n",
    "    if argmax:\n",
    "        pred_char = idx_to_char[argmax_idx.item()]\n",
    "    \n",
    "    return pred_char, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_n_from_seed(n, seed, model):\n",
    "    model = model.cpu()\n",
    "    output = seed\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n - len(output)):\n",
    "            c, h = predict_one(model, output)\n",
    "            output += c\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We all live in tidg in bebathoy thy fes hoodtim Biliratat\"-in in cuplliat cempithaly an the of burk steevl cusne, shimolakich oWolKe allaw to mozly ackove yur the wits aly af for aans the thikl- goke '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_n_from_seed(200, 'We all live in', rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
