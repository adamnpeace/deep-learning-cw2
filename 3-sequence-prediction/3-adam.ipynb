{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "!curl -fsS https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip -o /tmp/trainDevTestTrees_PTB.zip\n",
    "!unzip -q -o -d ./data /tmp/trainDevTestTrees_PTB.zip\n",
    "!rm -f /tmp/trainDevTestTrees_PTB.zip\n",
    "\n",
    "def loadsst(path):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    file1 = open(path, 'r')\n",
    "    Lines = file1.readlines()\n",
    "    for line in Lines:\n",
    "        soup = line.split()\n",
    "        ys.append(int(soup[0].lstrip('(')))\n",
    "        tokens = []\n",
    "        for chunk in soup[2:]:\n",
    "            if not chunk.endswith(\")\"):\n",
    "                continue\n",
    "            tokens.append(chunk.rstrip(')'))\n",
    "        xs.append(tokens)\n",
    "    return xs, ys\n",
    "\n",
    "ssttrainxs, ssttrainys = loadsst(\"./data/trees/train.txt\")\n",
    "sstvalidxs, sstvalidys = loadsst(\"./data/trees/dev.txt\")\n",
    "ssttestxs, ssttestys = loadsst(\"./data/trees/test.txt\")\n",
    "\n",
    "def normalize(s):\n",
    "    for i in range(len(s)):\n",
    "        replacements = [(\" ,\", \",\"), (\" .\", \".\"), (\" '\", \"'\"), \n",
    "                        (\"\\/\", \"/\"), (\" ;\", \";\"), (\" :\", \":\"),\n",
    "                        (\" %\", \"%\"), (u\"æ\", \"ae\"), (u\"Æ\", \"AE\"), \n",
    "                        (u\"œ\", \"oe\"), (u\"Œ\", \"OE\"), (\"-LRB- \", \"(\"), \n",
    "                        (\" -RRB-\", \")\"), (\"-LRB-\", \"(\"), (\"-RRB-\", \")\"),\n",
    "                        (\" n't\", \"n't\"), (\"`` \", '\"'), (\"``\", '\"'),\n",
    "                        (\"''\", '\"'), (\"` \", \"'\"), (\"$ \", \"$\"),\n",
    "                        (\" !\", \"!\"), (\"\\\\\", \"\")]\n",
    "        for to_replace, replacement in replacements:\n",
    "            s = s.replace(to_replace, replacement)\n",
    "    # https://stackoverflow.com/a/518232/2809427\n",
    "    def unicodeToAscii(s):\n",
    "        allowed_chars = string.ascii_letters + ' .,;:\\'-#!/\"=&$|_'\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "            and c in allowed_chars\n",
    "        )\n",
    "    return unicodeToAscii(s)\n",
    "\n",
    "def get_normalized_dataset(dataset):\n",
    "    return [normalize(\" \".join(sentence)) for sentence in dataset]\n",
    "\n",
    "trainxs_corpus = \"_\".join(get_normalized_dataset(ssttrainxs))\n",
    "validxs_corpus = \"_\".join(get_normalized_dataset(sstvalidxs))\n",
    "testxs_corpus = \"_\".join(get_normalized_dataset(ssttestxs))\n",
    "\n",
    "seq_len = 200\n",
    "\n",
    "corpus_to_ss = lambda corpus: [corpus[(i*200):((i+1)*200)] for i in range(len(corpus) // seq_len)]\n",
    "trainxs_sentences = corpus_to_ss(trainxs_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4292 sentences, 67 letters in vocab, max seq len is 200\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(list(set(trainxs_corpus)))\n",
    "n_sentences, vocab_size = len(trainxs_sentences), len(vocab)\n",
    "maxlen = len(max(trainxs_sentences, key=len))\n",
    "char_to_idx = { ch:idx for idx,ch in enumerate(vocab) }\n",
    "idx_to_char = { idx:ch for idx,ch in enumerate(vocab) }\n",
    "print(\"{} sentences, {} letters in vocab, max seq len is {}\".format(n_sentences, vocab_size, maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_inputs(sentences, maxlen):\n",
    "    for i in range(len(sentences)):\n",
    "        while len(sentences[i]) < maxlen:\n",
    "            sentences[i] += ' '\n",
    "    return sentences\n",
    "trainxs = pad_inputs(trainxs_sentences, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_target(ss):\n",
    "    \"\"\"Get input and target from padded sentences\"\"\"\n",
    "    input_ss = []\n",
    "    target_ss = []\n",
    "    for i in range(len(ss)):\n",
    "        input_ss.append([char_to_idx[c] for c in ss[i][:-1]])\n",
    "        target_ss.append([char_to_idx[c] for c in ss[i][1:]])\n",
    "    return input_ss, target_ss\n",
    "input_ss, target_ss = get_input_target(trainxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 48, 45, 0, 31, 55, 43, 51, 0, 49, 59, 0, 44, 45, 59, 60, 49, 54, 45, 44, 0, 60, 55, 0, 42, 45, 0, 60, 48, 45, 0, 59, 60, 0, 16, 45, 54, 60, 61, 58, 65, 6, 59, 0, 54, 45, 63, 0, 2, 16, 55, 54, 41, 54, 2, 0, 41, 54, 44, 0, 60, 48, 41, 60, 0, 48, 45, 6, 59, 0, 47, 55, 49, 54, 47, 0, 60, 55, 0, 53, 41, 51, 45, 0, 41, 0, 59, 56, 52, 41, 59, 48, 0, 45, 62, 45, 54, 0, 47, 58, 45, 41, 60, 45, 58, 0, 60, 48, 41, 54, 0, 14, 58, 54, 55, 52, 44, 0, 32, 43, 48, 63, 41, 58, 66, 45, 54, 45, 47, 47, 45, 58, 7, 0, 23, 45, 41, 54, 8, 16, 52, 41, 61, 44, 0, 35, 41, 54, 0, 17, 41, 53, 53, 45, 0, 55, 58, 0, 32, 60, 45, 62, 45, 54, 0, 32, 45, 47, 41, 52, 9, 40, 33, 48, 45, 0, 47, 55, 58, 47, 45, 55, 61, 59, 52, 65, 0, 45, 52, 41, 42, 55, 58, 41, 60, 45, 0, 43, 55]\n",
      "[48, 45, 0, 31, 55, 43, 51, 0, 49, 59, 0, 44, 45, 59, 60, 49, 54, 45, 44, 0, 60, 55, 0, 42, 45, 0, 60, 48, 45, 0, 59, 60, 0, 16, 45, 54, 60, 61, 58, 65, 6, 59, 0, 54, 45, 63, 0, 2, 16, 55, 54, 41, 54, 2, 0, 41, 54, 44, 0, 60, 48, 41, 60, 0, 48, 45, 6, 59, 0, 47, 55, 49, 54, 47, 0, 60, 55, 0, 53, 41, 51, 45, 0, 41, 0, 59, 56, 52, 41, 59, 48, 0, 45, 62, 45, 54, 0, 47, 58, 45, 41, 60, 45, 58, 0, 60, 48, 41, 54, 0, 14, 58, 54, 55, 52, 44, 0, 32, 43, 48, 63, 41, 58, 66, 45, 54, 45, 47, 47, 45, 58, 7, 0, 23, 45, 41, 54, 8, 16, 52, 41, 61, 44, 0, 35, 41, 54, 0, 17, 41, 53, 53, 45, 0, 55, 58, 0, 32, 60, 45, 62, 45, 54, 0, 32, 45, 47, 41, 52, 9, 40, 33, 48, 45, 0, 47, 55, 58, 47, 45, 55, 61, 59, 52, 65, 0, 45, 52, 41, 42, 55, 58, 41, 60, 45, 0, 43, 55, 54]\n"
     ]
    }
   ],
   "source": [
    "print(input_ss[0])\n",
    "print(target_ss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "seq_len = maxlen - 1\n",
    "batch_size = n_sentences\n",
    "n_epochs = 300\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(ss, vocab_size, seq_len, batch_size):\n",
    "    tensor = torch.zeros(batch_size, seq_len, vocab_size)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(seq_len):\n",
    "            tensor[i, j, ss[i][j]] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ohe = one_hot_encode(input_ss, vocab_size, seq_len, batch_size)\n",
    "target_tensor = torch.Tensor(target_ss) # No OHE necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available: device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/300............. Loss: 3.4778\n",
      "Epoch: 20/300............. Loss: 3.4418\n",
      "Epoch: 30/300............. Loss: 3.1740\n",
      "Epoch: 40/300............. Loss: 2.9741\n",
      "Epoch: 50/300............. Loss: 2.8564\n",
      "Epoch: 60/300............. Loss: 2.7667\n",
      "Epoch: 70/300............. Loss: 2.6974\n",
      "Epoch: 80/300............. Loss: 2.6532\n",
      "Epoch: 90/300............. Loss: 2.6149\n",
      "Epoch: 100/300............. Loss: 2.5804\n",
      "Epoch: 110/300............. Loss: 2.5512\n",
      "Epoch: 120/300............. Loss: 2.5264\n",
      "Epoch: 130/300............. Loss: 2.5054\n",
      "Epoch: 140/300............. Loss: 2.4874\n",
      "Epoch: 150/300............. Loss: 2.4714\n",
      "Epoch: 160/300............. Loss: 2.4570\n",
      "Epoch: 170/300............. Loss: 2.4440\n",
      "Epoch: 180/300............. Loss: 2.4322\n",
      "Epoch: 190/300............. Loss: 2.4215\n",
      "Epoch: 200/300............. Loss: 2.4117\n",
      "Epoch: 210/300............. Loss: 2.4026\n",
      "Epoch: 220/300............. Loss: 2.3943\n",
      "Epoch: 230/300............. Loss: 2.3865\n",
      "Epoch: 240/300............. Loss: 2.3792\n",
      "Epoch: 250/300............. Loss: 2.3724\n",
      "Epoch: 260/300............. Loss: 2.3661\n",
      "Epoch: 270/300............. Loss: 2.3601\n",
      "Epoch: 280/300............. Loss: 2.3546\n",
      "Epoch: 290/300............. Loss: 2.3494\n",
      "Epoch: 300/300............. Loss: 2.3446\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, 1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 2)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "#         output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "#         return torch.zeros(1, batch_size, self.hidden_size)\n",
    "        return torch.zeros(batch_size, 1, self.hidden_size)\n",
    "\n",
    "rnn = RNN(input_size=vocab_size, output_size=vocab_size, hidden_size=23)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=lr)\n",
    "\n",
    "rnn.to(device)\n",
    "\n",
    "def train(input_ohe, target_tensor, n_epochs):\n",
    "    loss_ary = []\n",
    "    target_tensor = target_tensor.to(device)\n",
    "    input_ohe = input_ohe.to(device)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        hidden = rnn.init_hidden(batch_size).to(device)\n",
    "        loss = 0\n",
    "        input_len = input_ohe.size(1)\n",
    "        for c_i in range(input_len):\n",
    "            output, hidden = rnn(input_ohe[:, c_i, :].unsqueeze(1), hidden)\n",
    "            loss += criterion(output.view(-1, vocab_size), target_tensor[:, c_i].long()) / input_len\n",
    "        \n",
    "        loss_ary.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch%10 == 0:\n",
    "            print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "            print(\"Loss: {:.4f}\".format(loss.item()))\n",
    "    return rnn, loss_ary\n",
    "rnn, loss_ary = train(input_ohe, target_tensor, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.8446271419525146, 5.565851783752441)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_plot = [(i, j) for i, j in enumerate(loss_ary) if i%1==0]\n",
    "plt.plot([i[0] for i in to_plot], [i[1] for i in to_plot])\n",
    "plt.ylim(min(loss_ary).item()-0.5, max(loss_ary).item()+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one(model, s, argmax=False):\n",
    "    batch_size = 1\n",
    "    s_tensor = torch.tensor([char_to_idx[c] for c in s]).unsqueeze(0)\n",
    "    s_ohe = one_hot_encode(s_tensor, vocab_size, s_tensor.size(1), batch_size)\n",
    "    hidden = model.init_hidden(batch_size)\n",
    "    for c_i in range(s_ohe.size(1)):\n",
    "#         output, hidden = rnn(s_ohe[:, c_i, :].unsqueeze(1), hidden)\n",
    "        \n",
    "    prob = F.softmax(output, dim=2)\n",
    "    \n",
    "    last_prob = prob[0, -1]\n",
    "    argmax_idx = last_prob.argmax()\n",
    "    sample_idx = last_prob.multinomial(num_samples=1, replacement=True)\n",
    "    pred_char = idx_to_char[sample_idx.item()]\n",
    "    if argmax:\n",
    "        pred_char = idx_to_char[argmax_idx.item()]\n",
    "    \n",
    "    return pred_char, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_n_from_seed(n, seed, model):\n",
    "    model = model.cpu()\n",
    "    output = seed\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n - len(output)):\n",
    "            c, h = predict_one(model, output)\n",
    "            output += c\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid multinomial distribution (encountering probability entry < 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-c9a24617a526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict_n_from_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'We all live in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-155-aff4140baa76>\u001b[0m in \u001b[0;36mpredict_n_from_seed\u001b[0;34m(n, seed, model)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-154-7fa2947dfa7e>\u001b[0m in \u001b[0;36mpredict_one\u001b[0;34m(model, s, argmax)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mlast_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0margmax_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mpred_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid multinomial distribution (encountering probability entry < 0)"
     ]
    }
   ],
   "source": [
    "predict_n_from_seed(200, 'We all live in', rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
